{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from support_functions import *\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from qiskit_experiments.library import QuantumVolume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the noise model for quantum volume circuits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_keys(q):\n",
    "    \"\"\"\n",
    "    All q qubit keys.\n",
    "    \"\"\"\n",
    "    keys = []\n",
    "    vector = [0 for _ in range(q)]\n",
    "    while(vector[-1]<2):\n",
    "        keystr = ''\n",
    "        for b in vector:\n",
    "            keystr += str(b)\n",
    "        keys.append(keystr)\n",
    "        \n",
    "        vector[0] += 1\n",
    "        for i in range(0,q-1):\n",
    "            if( vector[i] >= 2):\n",
    "                vector[i] = 0\n",
    "                vector[i+1] += 1\n",
    "            else:\n",
    "                break\n",
    "    return keys\n",
    "\n",
    "#allkeys = all_keys(6)\n",
    "#print(allkeys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generate_QuantumVolumeCircuits(nr_qubits, nr_of_circuits):\n",
    "    \"\"\"\n",
    "    Generate a number of quantum volume circuits.\n",
    "    \"\"\"\n",
    "    qv = QuantumVolume([i for i in range(nr_qubits)], trials=nr_of_circuits)\n",
    "    circs = qv.circuits()\n",
    "    return circs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 24\n",
    "N = 1000\n",
    "n_tests = 20#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HU_found(circ, noise_thermal, nr_qubits):\n",
    "    \"\"\"\n",
    "    Detmerine the fraction of heavy outputs.\n",
    "    \"\"\"\n",
    "    tdc = transpile(circ.decompose(reps=2), basis_gates=load_noise_thermal().basis_gates, coupling_map=get_coupling_map(nr_qubits), optimization_level=3)\n",
    "    \n",
    "    counts1 = clean_exc(tdc)\n",
    "    srt_lst1 = []\n",
    "    for key in all_keys(nr_qubits):\n",
    "        k = key\n",
    "        l = 0\n",
    "        if key in counts1.keys():\n",
    "            l = counts1[key]\n",
    "        insert = 0\n",
    "        for i in range(len(srt_lst1)):\n",
    "            if( l > srt_lst1[i][1] ):\n",
    "                srt_lst1.insert(i,[k,l].copy())\n",
    "                insert=1\n",
    "                break\n",
    "        if(insert==0):\n",
    "            srt_lst1.append([k,l].copy())\n",
    "    HU1 = [ k for [k,_] in srt_lst1[0:int(2**(nr_qubits-1))] ] \n",
    "    f_ho = sum(  l for [_,l] in srt_lst1[0:int(2**(nr_qubits-1))]  ) / sum(  l for [_,l] in srt_lst1  )\n",
    "    #print(f_ho)\n",
    "    \n",
    "    nr_heavy_outputs = 0\n",
    "    nr_measurements = 0;\n",
    "    \n",
    "    counts2 = noisy_exc(tdc, noise_thermal)\n",
    "    srt_lst2 = []\n",
    "    for key in counts2.keys():\n",
    "        k = key\n",
    "        l = counts2[key]\n",
    "        nr_measurements += l\n",
    "        if k in HU1:\n",
    "            nr_heavy_outputs += l\n",
    "        \n",
    "            \n",
    "    return nr_heavy_outputs/nr_measurements, nr_measurements, f_ho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"\"\"\n",
    "IBMQ.load_account()\n",
    "\n",
    "# listing the providers you have access to \n",
    "IBMQ.providers()\n",
    "# Use your provider to access \"premium\" devices\n",
    "provider = IBMQ.get_provider(hub='', group='', project='')\n",
    "# listing backends your provider have access to \n",
    "provider.backends()\n",
    "\n",
    "# Selecting ibm_perth\n",
    "backend = provider.get_backend('ibm_perth')\n",
    "print(backend.name())\n",
    "noise_perth = NoiseModel.from_backend(backend)\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QV-experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_results(results, b_d, c_d, b_s, c_s):\n",
    "    \"\"\"\n",
    "    Determine the remaining loss for given noise model parameters.\n",
    "    Both noise models based on the depth and the size of the circuit are considered.\n",
    "    \"\"\"\n",
    "    loss_s = 0.0\n",
    "    loss_d = 0.0\n",
    "    for [q, ctr, agd, ags, a] in results:\n",
    "        power_d = (agd/100)*(7/q)\n",
    "        power_s = (ags/100)#*(7/q)\n",
    "        a_d = b_d * (c_d**power_d)\n",
    "        a_s = b_s * (c_s**power_s)\n",
    "        loss_d += ctr * (a-a_s)**2\n",
    "        loss_s += ctr * (a-a_s)**2\n",
    "    return loss_d, loss_s\n",
    "\n",
    "def find_bc(results):\n",
    "    \"\"\"\n",
    "    Find the best parameters for noise model based on both depth and size.\n",
    "    \"\"\"\n",
    "    b_s = 1.0\n",
    "    c_s = 0.5\n",
    "    b_d = 1.0\n",
    "    c_d = 0.5\n",
    "    loss_d, loss_s = loss_results(results, b_d, c_d, b_s, c_s)\n",
    "    \n",
    "    for i in range(100):\n",
    "        for j in range(100):\n",
    "            bd2 = 1.000 - 0.002*i\n",
    "            cd2 = 0.01*j\n",
    "            loss2d, _ = loss_results(results, bd2, cd2, b_s, c_s)\n",
    "            if(loss2d<loss_d):\n",
    "                b_d = bd2\n",
    "                c_d = cd2\n",
    "                loss_d = loss2d\n",
    "    \n",
    "    for i in range(100):\n",
    "        for j in range(100):\n",
    "            bs2 = 1.000 - 0.002*i\n",
    "            cs2 = 0.01*j\n",
    "            _, loss2s = loss_results(results, b_d, c_d, bs2, cs2)\n",
    "            if(loss2s<loss_s):\n",
    "                b_s = bs2\n",
    "                c_s = cs2\n",
    "                loss_s = loss2s\n",
    "\n",
    "    return b_d, c_d, loss_d, b_s, c_s, loss_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Perform QV experiments with a noise model simulating Perth and determine the noise model parameters afterwards.\n",
    "results = []\n",
    "for q in range(4,11):\n",
    "    nh = 0\n",
    "    nc = n_tests \n",
    "    ns = -1\n",
    "    fho_avg = 0.0\n",
    "    x_avg = 0\n",
    "    x_var = 0\n",
    "    ctr = n_tests\n",
    "    avg_gate_depth = 0\n",
    "    avg_gate_size = 0\n",
    "    circs = Generate_QuantumVolumeCircuits(q, n_tests)\n",
    "    for i in range(n_tests):\n",
    "        circ = circs[i]\n",
    "        tdc = transpile(circ.decompose(reps=2), basis_gates=load_noise_thermal().basis_gates, coupling_map=get_coupling_map(q), optimization_level=3)\n",
    "        avg_gate_depth += tdc.depth()\n",
    "        avg_gate_size += tdc.size()\n",
    "        x, n, f_ho = HU_found(circ, noise_perth, q)\n",
    "        fho_avg += f_ho\n",
    "        if(ns==-1):\n",
    "            ns = n\n",
    "        elif( n!=ns ):\n",
    "            print(\"Different number of shots:\", n, ns)\n",
    "        nh += x*n\n",
    "\n",
    "        if( (x<0) | (x>1)):\n",
    "            print(\"Erroroneous value for x: \", x)\n",
    "        x_avg += x\n",
    "        x_var += x*(1-x)\n",
    "        \n",
    "    x_avg = x_avg\n",
    "    x_var = x_var\n",
    "    x_std = np.sqrt(x_var)\n",
    "    z = (x_avg-((2*ctr)/3))/x_std\n",
    "    z2 = ( nh - (nc*ns*2/3) ) / np.sqrt(nh*(ns-(nh/nc)))\n",
    "    a = ((x_avg/ctr) - 0.5 ) / ((fho_avg/ctr) - 0.5)\n",
    "    ap = (0.97**q)*(0.16**(avg_gate_size/(ctr*100)))\n",
    "    ap2 = (0.97**q)*(0.16**(avg_gate_size*7/(q*ctr*100)))\n",
    "    \n",
    "    results.append([q, ctr, avg_gate_depth/ctr, avg_gate_size/ctr, a])\n",
    "    print(q, round(avg_gate_depth/ctr,1), round(avg_gate_size/ctr,1), round(fho_avg/ctr,2), round(avg_gate_size/avg_gate_depth,1), round(a,2), round(ap,2), round(ap2,2))\n",
    "    print(\"\\t\", ctr, round(x_avg/ctr,2), round(x_std/ctr,2), round(z,2), z > 2, round(z2,2))\n",
    "    \n",
    "print( find_bc(results) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Perform QV experiments with a thermal noise model based on Perth and determine the noise model parameters afterwards.\n",
    "noise_thermal = load_noise_thermal()\n",
    "results = []\n",
    "for q in range(4,11):\n",
    "    nh = 0\n",
    "    nc = n_tests \n",
    "    ns = -1\n",
    "    fho_avg = 0.0\n",
    "    x_avg = 0\n",
    "    x_var = 0\n",
    "    ctr = n_tests\n",
    "    avg_gate_depth = 0\n",
    "    avg_gate_size = 0\n",
    "    circs = Generate_QuantumVolumeCircuits(q, n_tests)\n",
    "    for i in range(n_tests):\n",
    "        circ = circs[i]\n",
    "        tdc = transpile(circ.decompose(reps=2), basis_gates=load_noise_thermal().basis_gates, coupling_map=get_coupling_map(q), optimization_level=3)\n",
    "        avg_gate_depth += tdc.depth()\n",
    "        avg_gate_size += tdc.size()\n",
    "        x, n, f_ho = HU_found(circ, noise_thermal, q)\n",
    "        fho_avg += f_ho\n",
    "        if(ns==-1):\n",
    "            ns = n\n",
    "        elif( n!=ns ):\n",
    "            print(\"Different number of shots:\", n, ns)\n",
    "        nh += x*n\n",
    "\n",
    "        if( (x<0) | (x>1)):\n",
    "            print(\"Erroroneous value for x: \", x)\n",
    "        x_avg += x\n",
    "        x_var += x*(1-x)\n",
    "        \"\"\"\n",
    "        if( (i>=19) & ( (x_avg-((i+1)*2/3))/np.sqrt(x_var) > 2.0 ) ):\n",
    "            ctr = i+1\n",
    "            nc = i+1\n",
    "            break\n",
    "        elif( (i>=19) & ( (x_avg-((i+1)*2/3))/np.sqrt(x_var) < 0.0 ) ):\n",
    "            ctr = i+1\n",
    "            nc = i+1\n",
    "            break\n",
    "        \"\"\"\n",
    "    x_avg = x_avg\n",
    "    x_var = x_var\n",
    "    x_std = np.sqrt(x_var)\n",
    "    z = (x_avg-((2*ctr)/3))/x_std\n",
    "    z2 = ( nh - (nc*ns*2/3) ) / np.sqrt(nh*(ns-(nh/nc)))\n",
    "    a = ((x_avg/ctr) - 0.5 ) / ((fho_avg/ctr) - 0.5)\n",
    "    ap = (0.97**q)*(0.16**(avg_gate_size/(ctr*100)))\n",
    "    ap2 = (0.97**q)*(0.16**(avg_gate_size*7/(q*ctr*100)))\n",
    "    \n",
    "    results.append([q, ctr, avg_gate_depth/ctr, avg_gate_size/ctr, a])\n",
    "    print(q, round(avg_gate_depth/ctr,1), round(avg_gate_size/ctr,1), round(fho_avg/ctr,2), round(avg_gate_size/avg_gate_depth,1), round(a,2), round(ap,2), round(ap2,2)) \n",
    "    print(\"\\t\", ctr, round(x_avg/ctr,2), round(x_std/ctr,2), round(z,2), z > 2, round(z2,2))\n",
    "    \n",
    "print( find_bc(results) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Perform QV experiments with an empty noise model and determine the noise model parameters afterwards.\n",
    "#For test purposes only.\n",
    "noise_model_1 = NoiseModel()\n",
    "results = []\n",
    "for q in range(4,8):\n",
    "    nh = 0\n",
    "    nc = n_tests \n",
    "    ns = -1\n",
    "    fho_avg = 0.0\n",
    "    x_avg = 0\n",
    "    x_var = 0\n",
    "    ctr = n_tests\n",
    "    avg_gate_depth = 0\n",
    "    avg_gate_size = 0\n",
    "    circs = Generate_QuantumVolumeCircuits(q, n_tests)\n",
    "    for i in range(n_tests):\n",
    "        circ = circs[i]\n",
    "        tdc = transpile(circ.decompose(reps=2), basis_gates=load_noise_thermal().basis_gates, coupling_map=get_coupling_map(q), optimization_level=3)\n",
    "        avg_gate_depth += tdc.depth()\n",
    "        avg_gate_size += tdc.size()\n",
    "        x, n, f_ho = HU_found(circ, noise_model_1, q)\n",
    "        fho_avg += f_ho\n",
    "        if(ns==-1):\n",
    "            ns = n\n",
    "        elif( n!=ns ):\n",
    "            print(\"Different number of shots:\", n, ns)\n",
    "        nh += x*n\n",
    "\n",
    "        if( (x<0) | (x>1)):\n",
    "            print(\"Erroroneous value for x: \", x)\n",
    "        x_avg += x\n",
    "        x_var += x*(1-x)\n",
    "    x_avg = x_avg\n",
    "    x_var = x_var\n",
    "    x_std = np.sqrt(x_var)\n",
    "    z = (x_avg-((2*ctr)/3))/x_std\n",
    "    z2 = ( nh - (nc*ns*2/3) ) / np.sqrt(nh*(ns-(nh/nc)))\n",
    "    a = ((x_avg/ctr) - 0.5 ) / ((fho_avg/ctr) - 0.5)\n",
    "    \n",
    "    results.append([q, ctr, avg_gate_depth/ctr, avg_gate_size/ctr, a])\n",
    "    print(q, round(avg_gate_depth/ctr,1), round(avg_gate_size/ctr,1), round(fho_avg/ctr,2), \n",
    "          round(avg_gate_size/avg_gate_depth,1), round(a,2) )\n",
    "    print(\"\\t\", ctr, round(x_avg/ctr,2), round(x_std/ctr,2), round(z,2), z > 2, round(z2,2))\n",
    "    \n",
    "print( find_bc(results) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QV circuit statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Analyze the probabilities, size and depth of quantum volume circuits.\n",
    "q = 7\n",
    "circs = Generate_QuantumVolumeCircuits(q, n_tests)\n",
    "avg_depth = 0.0\n",
    "avg_size = 0.0\n",
    "W1 = [ ]\n",
    "W2 = [ ]\n",
    "for j in range(n_tests):\n",
    "    circ = circs[j]\n",
    "    tdc = transpile(circ.decompose(reps=2), basis_gates=load_noise_thermal().basis_gates, coupling_map=get_coupling_map(q), optimization_level=3)\n",
    "    avg_depth += tdc.depth() / n_tests\n",
    "    avg_size += tdc.size() / n_tests\n",
    "    counts1 = clean_exc(tdc)\n",
    "    counts2 = noisy_exc(tdc, noise_thermal)\n",
    "      \n",
    "    for key in all_keys(q):\n",
    "        k = key\n",
    "        l1 = 0.0\n",
    "        l2 = 0.0\n",
    "        if key in counts1.keys():\n",
    "            l1 = counts1[key]/Nr_shots\n",
    "        if key in counts2.keys():\n",
    "            l2 = counts2[key]/Nr_shots\n",
    "        insert = 0\n",
    "        for i in range(len(W1)):\n",
    "            if( l1 < W1[i] ):\n",
    "                W1.insert(i,l1)\n",
    "                insert=1\n",
    "                break\n",
    "        if(insert==0):\n",
    "            W1.append(l1)\n",
    "        insert = 0\n",
    "        for i in range(len(W2)):\n",
    "            if( l2 < W2[i] ):\n",
    "                W2.insert(i,l2)\n",
    "                insert=1\n",
    "                break\n",
    "        if(insert==0):\n",
    "            W2.append(l2)\n",
    "print(\"Average depth:\", avg_depth)\n",
    "print(\"Average size:\", avg_size)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p(x,labda):\n",
    "    Labda = labda / (labda-1+np.exp(-labda))\n",
    "    return (1-x)*labda*np.exp(-labda*x)*Labda\n",
    "\n",
    "def p_scores(labda_p, b, bin_width):\n",
    "    weight_p = [0.0 for _ in range(b)]\n",
    "    for i in range(N):\n",
    "        x = (i+0.5)*b*bin_width/N\n",
    "        n = int(x//bin_width)\n",
    "        if(n<b):\n",
    "            weight_p[n] += p(x,labda_p)*b*bin_width/N\n",
    "        else:\n",
    "            break\n",
    "    return weight_p\n",
    "\n",
    "def nd(x,mu, sigma):\n",
    "    return np.exp(-0.5*(((x-mu)/sigma)**2)) / np.sqrt(2*np.pi*sigma*sigma)\n",
    "\n",
    "def p_err_scores(labda_p, q, sigma, err_par, b, bin_width):\n",
    "    weight_p_err = [0.0 for _ in range(b)]\n",
    "    for i in range(N):\n",
    "        x = (i+0.5)*b*bin_width/N\n",
    "        n = int(x//bin_width)\n",
    "        if(n<b):\n",
    "            weight_p_err[n] += ( (1-err_par) * p(x,labda_p) + err_par * nd(x,2**(-q), sigma) ) * b * bin_width / N\n",
    "        else:\n",
    "            break\n",
    "    return weight_p_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_width = 1.01*max((W1[-1])/b,(W2[-1])/b)\n",
    "ctr_lst1 = [0 for _ in range(b) ]\n",
    "for x in W1:\n",
    "    n = int(x//bin_width)\n",
    "    if(n<b):\n",
    "        ctr_lst1[n] += 1/len(W1)\n",
    "print([round(x,3) for x in ctr_lst1])\n",
    "lenW1 = len(W1)\n",
    "print(lenW1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labda = 2**q\n",
    "weight_p = p_scores(labda, b, bin_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the observed probabilities\n",
    "fig,ax = plt.subplots()\n",
    "ax.hist(W1, bins=np.arange(0.0,1.01*W1[-1],bin_width), density=True)\n",
    "X = [ 1.01*(W1[-1]) * 0.001 * (i+0.5) for i in range(1000) ]\n",
    "ax.plot(X,[ p(x,labda) for x in X ])\n",
    "\n",
    "ax.legend(['PS', 'hist W1'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr_lst2 = [0 for _ in range(b) ]\n",
    "for x in W2:\n",
    "    n = int(x//bin_width)\n",
    "    if(n<b):\n",
    "        ctr_lst2[n] += 1/len(W2)\n",
    "print([round(x,3) for x in ctr_lst2])\n",
    "lenW2 = len(W2)\n",
    "print(lenW2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noisy QV circuits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of pure noise, every outcome is equally likely and we expect a peak in the histogram at this point. Statistical fluctuations will make this a normal distribution with a mean of $2^{-q}$. The standard deviation is given by $2/N$.\n",
    "\n",
    "This can be used to fit the error parameter from a series of noisy QV experiments. In the distribution of the probabilities a normal distribution will appear in the exponential distribution. Fitting this as good as possible may tell the success rate for a error-free execution.\n",
    "\n",
    "Theoretically, we expect that a QV experiment will fail, if the probability of an error-fre run sinks below $a=0.48$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labda = 2**q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.hist(W2, bins=np.arange(0.0,W2[-1],bin_width/2), density=True)\n",
    "X = [ 1.01*(W2[-1]) * 0.001 * (i+0.5) for i in range(1000) ]\n",
    "ax.plot(X,[ p(x,labda) for x in X ])\n",
    "\n",
    "ax.legend(['PS_err', 'hist W2'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def random_answers(q, nr_shots):\n",
    "    keys = all_keys(q)\n",
    "    counts = {}\n",
    "    for key in keys:\n",
    "        counts[key] = 0\n",
    "    for _ in range(nr_shots):\n",
    "        k = np.random.choice(keys)\n",
    "        counts[k] += 1\n",
    "    return counts\n",
    "\n",
    "nr_shots = Nr_shots\n",
    "W3 = [ ]\n",
    "for j in range(n_tests):\n",
    "    counts3 = random_answers(q, nr_shots)\n",
    "\n",
    "    for key in all_keys(q):\n",
    "        k = key\n",
    "        l3 = 0.0\n",
    "        if key in counts3.keys():\n",
    "            l3 = counts3[key]/nr_shots\n",
    "        insert = 0\n",
    "        for i in range(len(W3)):\n",
    "            if( l3 < W3[i] ):\n",
    "                W3.insert(i,l3)\n",
    "                insert=1\n",
    "                break\n",
    "        if(insert==0):\n",
    "            W3.append(l3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "bin_width3 = 1.01*W3[-1] / b\n",
    "ax.hist(W3, bins=np.arange(0.0,1.01*W3[-1],bin_width3), density=True)\n",
    "X = [ 1.01*(W3[-1]) * 0.001 * (i+0.5) for i in range(1000) ]\n",
    "mu = 2**(-q)\n",
    "sigma = np.sqrt( mu*(1-mu)/nr_shots )\n",
    "ax.plot(X,[ nd(x,mu, sigma) for x in X ])\n",
    "\n",
    "ax.legend(['Norm dist', 'hist W1'])\n",
    "#plt.savefig('purenoise.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mu, np.sqrt( mu*(1-mu)/(nr_shots) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labda = 2**q\n",
    "mu = 2**(-q)\n",
    "err_par = 0.5\n",
    "sigma = np.sqrt( mu*(1-mu)/(err_par * nr_shots) )\n",
    "\n",
    "weight_p_err = p_err_scores(labda, q, np.sqrt( mu*(1-mu)/(err_par * nr_shots) ), err_par, b, bin_width)\n",
    "best_diff = sum( abs( weight_p_err[i] - ctr_lst2[i] )**2 for i in range(b) )\n",
    "\n",
    "cont = 1\n",
    "while cont==1 :\n",
    "    cont = 0\n",
    "    err_lst = []\n",
    "    for i in range(1,20):\n",
    "        if(err_par + 0.01*i <= 1.0):\n",
    "            err_lst.append(err_par + 0.01*i)\n",
    "        if(err_par - 0.01*i >= 0.0):\n",
    "            err_lst.append(err_par - 0.01*i)\n",
    "    #print(err_lst)\n",
    "    for ep in err_lst:\n",
    "        weight_p_dummy = p_err_scores(labda, q, np.sqrt( mu*(1-mu)/(ep * nr_shots) ), ep, b, bin_width)\n",
    "        abs_diff = sum( abs( weight_p_dummy[i] - ctr_lst2[i] )**2 for i in range(b) )\n",
    "        if(abs_diff<best_diff):\n",
    "            best_diff = abs_diff\n",
    "            err_par = ep\n",
    "            cont = 1\n",
    "\n",
    "\n",
    "print(round(np.sqrt(best_diff),3), err_par)\n",
    "weight_p_err = p_err_scores(labda, q, 2/(2*err_par*n_tests), err_par, b, bin_width)\n",
    "for i in range(b):\n",
    "    print(i, round(ctr_lst2[i], 2), round(weight_p_err[i], 2))\n",
    "\n",
    "a = 1-err_par\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.hist(W2, bins=np.arange(0.0,W2[-1],bin_width/2), density=True)\n",
    "X = [ 1.01*(W2[-1]) * 0.001 * (i+0.5) for i in range(1000) ]\n",
    "ax.plot(X,[ p(x,labda) for x in X ])\n",
    "\n",
    "ax.plot(X,[ a * p(x,labda) + (1-a) * nd(x, 2**(-q), sigma) for x in X ])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_gate_depth = 21.521\n",
    "avg_gate_size = 38.973\n",
    "\n",
    "power = (avg_gate_depth/100)\n",
    "c = (a/(0.99**q))**(1/power)\n",
    "print(c, power, q, avg_gate_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "powers = (avg_gate_size/100)\n",
    "cs = (a/(0.99**q))**(1/powers)\n",
    "print(cs, powers, q, avg_gate_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
